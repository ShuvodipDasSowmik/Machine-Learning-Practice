{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "efdb2dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd1e93a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Age         177\n",
       "Cabin       687\n",
       "Embarked      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file_path = '../Data/train.csv'\n",
    "test_file_path = '../Data/test.csv'\n",
    "\n",
    "train_data = pd.read_csv(train_file_path)\n",
    "test_data = pd.read_csv(test_file_path)\n",
    "\n",
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return accuracy_score(y_valid, (preds > 0.5).astype(int))\n",
    "\n",
    "cols_with_missing_values = [col for col in train_data.columns if train_data[col].isnull().any()]\n",
    "\n",
    "print(train_data.shape)\n",
    "train_data[cols_with_missing_values].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc04ac1",
   "metadata": {},
   "source": [
    "- Remove Cabin Column\n",
    "- Remove rows with missing values of Embarked\n",
    "- Impute values for Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47a92772",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop(columns=['Cabin'], axis=1)\n",
    "test_data = test_data.drop(columns=['Cabin'], axis=1)\n",
    "\n",
    "train_data = train_data.dropna(subset=['Embarked'])\n",
    "test_data = test_data.dropna(subset=['Embarked'])\n",
    "\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "train_data['Age'] = imputer.fit_transform(train_data[['Age']])\n",
    "test_data['Age'] = imputer.transform(test_data[['Age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "430c144d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Columns: Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Embarked'],\n",
      "      dtype='object')\n",
      "Categorical Columns: ['Name', 'Sex', 'Ticket', 'Embarked']\n",
      "Low Cardinality Columns: ['Sex', 'Embarked']\n",
      "Numeric Columns: ['PassengerId', 'Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
      "All Selected Columns: ['PassengerId', 'Embarked', 'Age', 'Fare', 'Parch', 'SibSp', 'Sex', 'Pclass']\n",
      "Ticket Carditnality: 680\n"
     ]
    }
   ],
   "source": [
    "# Categorical variables, and cardinality or the categorical variables\n",
    "print(\"Train Data Columns:\", train_data.columns)\n",
    "\n",
    "categorical_cols = [col for col in train_data.columns if train_data[col].dtype == 'object']\n",
    "print(\"Categorical Columns:\", categorical_cols)\n",
    "\n",
    "low_cardinality_cols = [col for col in categorical_cols if train_data[col].nunique() < 10]\n",
    "print(\"Low Cardinality Columns:\", low_cardinality_cols)\n",
    "\n",
    "numeric_cols = [col for col in train_data.columns if train_data[col].dtype in ['int64', 'float64']]\n",
    "print(\"Numeric Columns:\", numeric_cols)\n",
    "\n",
    "all_cols = low_cardinality_cols + numeric_cols\n",
    "all_cols = set(all_cols) - set(['Survived'])\n",
    "all_cols = list(all_cols)\n",
    "\n",
    "print(\"All Selected Columns:\", all_cols)\n",
    "\n",
    "print(\"Ticket Carditnality:\", train_data['Ticket'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fafc4aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_data.Survived\n",
    "X = train_data[all_cols]\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36404303",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "OE = OrdinalEncoder()\n",
    "label_X_train = X_train.copy()\n",
    "label_X_valid = X_valid.copy()\n",
    "\n",
    "label_X_train[low_cardinality_cols] = OE.fit_transform(X_train[low_cardinality_cols])\n",
    "label_X_valid[low_cardinality_cols] = OE.transform(X_valid[low_cardinality_cols])\n",
    "\n",
    "OH = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "OH_X_train = X_train.copy()\n",
    "OH_X_valid = X_valid.copy()\n",
    "\n",
    "OH_X_train = pd.DataFrame(OH.fit_transform(X_train[low_cardinality_cols]))\n",
    "OH_X_valid = pd.DataFrame(OH.transform(X_valid[low_cardinality_cols]))\n",
    "\n",
    "OH_X_train.index = X_train.index\n",
    "OH_X_valid.index = X_valid.index\n",
    "\n",
    "OH_X_train.columns = OH_X_train.columns.astype(str)\n",
    "OH_X_valid.columns = OH_X_valid.columns.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "136e80be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Ordinal Encoding): 0.7528089887640449\n",
      "Accuracy (One-Hot Encoding): 0.7191011235955056\n"
     ]
    }
   ],
   "source": [
    "OE_preds = score_dataset(label_X_train, label_X_valid, y_train, y_valid)\n",
    "print(\"Accuracy (Ordinal Encoding):\", OE_preds)\n",
    "\n",
    "OH_preds = score_dataset(OH_X_train, OH_X_valid, y_train, y_valid)\n",
    "print(\"Accuracy (One-Hot Encoding):\", OH_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd4e84b",
   "metadata": {},
   "source": [
    "## Data Leakage Fix\n",
    "\n",
    "**Problem Fixed**: The previous approach trained a model on the full dataset and then evaluated it on a subset of that same data, causing data leakage and artificially high accuracy (1.0).\n",
    "\n",
    "**Solution**: \n",
    "1. Use proper train/validation split for model evaluation\n",
    "2. Train final model on full dataset only for submission (no evaluation)\n",
    "3. Use separate encoder for final model to avoid contamination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5edb9820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model trained on full dataset - ready for predictions\n"
     ]
    }
   ],
   "source": [
    "# Train final model on full dataset for submission (no evaluation to avoid leakage)\n",
    "full_X_train = train_data[all_cols]\n",
    "\n",
    "# Re-fit encoder on full training data for final model\n",
    "label_X_full = full_X_train.copy()\n",
    "OE_full = OrdinalEncoder()\n",
    "label_X_full[low_cardinality_cols] = OE_full.fit_transform(full_X_train[low_cardinality_cols])\n",
    "\n",
    "# Train final model on full dataset\n",
    "final_model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "final_model.fit(label_X_full, y)\n",
    "\n",
    "print(\"Final model trained on full dataset - ready for predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb18b8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file created: titanic_OE_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on test data using the final model\n",
    "test_X = test_data[all_cols]\n",
    "\n",
    "label_X_test = test_X.copy()\n",
    "label_X_test[low_cardinality_cols] = OE_full.transform(test_X[low_cardinality_cols])\n",
    "\n",
    "OE_test_preds = final_model.predict(label_X_test)\n",
    "OE_test_preds = (OE_test_preds > 0.5).astype(int)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"PassengerId\": test_data.PassengerId,\n",
    "    \"Survived\": OE_test_preds\n",
    "})\n",
    "\n",
    "submission.to_csv('titanic_OE_submission.csv', index=False)\n",
    "print(\"Submission file created: titanic_OE_submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
